# DoWhyDissertationProject

This repository contains both my Master's dissertation as well as the source code. The purpose of the project was to build a regressor that incorporated the DoWhy causal inference package and to test its efficacy compared to that of the scikit-learn regressors. For the project I compiled a dataset of suicide rates by country, broken down by demographic and by year, alongside socioeconomic data for the corresponding countries and years. Links to the online datasets that I used as the source for my dataset are cited in the source code document.

I built to different regressors using DoWhy. The more effective was one that used gradient descent to estimate the strength of unobserved confounding variables that aren't in the dataset. This model assumes causal independence between all feature variables, but subsequently performs a sensitivity analysis on the initisl coefficients by testing how robustly they predict the target variable when combined with simulated unobserved confounders. The estimated strength of these unobserved variables is updated each epoch with gradient descent. This model outperformed standard linear regressors and decision trees regressors on the dataset in question. 

The other regressor estimated coefficients based on a model of causal relationships between feature variables that was learnt via a genetic algorithm. It proved  considerably less accurate. Additionally, it was also extremely computationally expensive - in spite of the fact that the genetic algorithm only searched a tiny proportion of the possibility space and failed to reliably converge upon similar candidates. The purpose of the genetic algorithm was to learn the causal graphical model of confounding relationships that most effectively predicted the training data. A distinguishing feature of DoWhy is that is uses directed-acyclic-graphics to determine which variables to control for when estimating coefficients. The genetic algorithm tests a range of candidates for each epoch, then selects the two graphics that result in the lowest loss as ancestors for the subsequent generation of variations.

The model which used gradient descent to estimate the strength of unobserved confounders outperformed linear regressors and decision tree regressors on the dataset in question. This could be due to the fact that the feature variables in the dataset only hazily predicted the target variable. This would have given the DoWhy regressor an edge, given its strength is in testing how much predictive power feature variables would have when placed alongside unobserved confounders. It's therefore likely that this regressor would be most likely to outperform standard scikit-learn regressors on datasets where the feature variables are highly imperfect predictors of the target variable.
